- [经典论文](#经典论文)
- [REID](#reid)
  - [Bag of Tricks and A Strong Baseline for Deep Person Re-identification](#bag-of-tricks-and-a-strong-baseline-for-deep-person-re-identification)
  - [Deep Learning for Person Re-identification:A Survey and Outlook](#deep-learning-for-person-re-identificationa-survey-and-outlook)
  - [Learning Discriminative Features with Multiple Granularities for Person Re-Identification](#learning-discriminative-features-with-multiple-granularities-for-person-re-identification)
  - [Learning Generalisable Omni-Scale Representations for Person Re-Identification](#learning-generalisable-omni-scale-representations-for-person-re-identification)
  - [Parsing-based View-aware Embedding Network for Vehicle Re-Identification](#parsing-based-view-aware-embedding-network-for-vehicle-re-identification)
- [目标检测](#目标检测)
  - [yolov8](#yolov8)
- [重参数化](#重参数化)

## 经典论文

...

## REID

### [Bag of Tricks and A Strong Baseline for Deep Person Re-identification](https://openaccess.thecvf.com/content_CVPRW_2019/papers/TRMTMCT/Luo_Bag_of_Tricks_and_a_Strong_Baseline_for_Deep_Person_CVPRW_2019_paper.pdf)

1. Warmup,
2. Random Erasing,
3. Label Smoothing,
4. 最后一个stride从2改为1，计算量不会增加很多,
5. 作者认为ID-loss是对特征划分超平面，类间距离会很明显，类内分布不明确；triptle-loss 是对特征聚合，没有全局约束；直接结合两者的损失会训不好，因为两种损失的所带来特征分布是有极大区别，所以需要卷积进行过渡，在输出的两个上分别作损失计算
6. 作者认为triplet-loss只考虑的特征之间的绝对距离，所以增加一个center-loss来改善类内特征的紧密性
7. 消融实验中，作者认为batch_size的选择很重要，要兼顾类间和类内，并且认为图片尺寸对REID没有影响

可用trick
Bag of Freebies(BoF):

1. Circle loss
2. Freeze backbone training
3. Cutout data augmentation & Auto Augmentation
4. Cosine annealing learning rate decay
5. Soft margin triplet loss

Bag of Specials(BoS):

1. Non-local block
2. GeM pooling

### [Deep Learning for Person Re-identification:A Survey and Outlook](https://arxiv.org/pdf/2001.04193v2.pdf)

1. Non-local Attention
2. Generalized-mean Pooling
3. Weighted Regularization Triplet loss
   代码在[fast-reid](https://github.com/JDAI-CV/fast-reid/tree/39887a102eeec84661f0c0332000f8138aa9109d)

### [Learning Discriminative Features with Multiple Granularities for Person Re-Identification](https://arxiv.org/pdf/1804.01438v1.pdf)

基于高级语义特征，多分支，沿着垂直方向分成若干个stripe，在对每一个stripe产生的特征做损失，推理时对多分枝的特征进行堆叠

### [Learning Generalisable Omni-Scale Representations for Person Re-Identification](https://arxiv.org/pdf/1910.06827v5.pdf)

1. 采用DW卷积
2. 将单分支bottleneck改成改成多分支，并用gate把多尺寸特征进行结合
3. 插入Instance Normalisation，有助于去除图像风格带来的差异

### [Parsing-based View-aware Embedding Network for Vehicle Re-Identification](https://openaccess.thecvf.com/content_CVPR_2020/papers/Meng_Parsing-Based_View-Aware_Embedding_Network_for_Vehicle_Re-Identification_CVPR_2020_paper.pdf)

1. 使用图像分割网络把汽车解构成几个子部分，再用带掩膜的平均池化提取子部分的高级语义嵌入特征，并使用这些嵌入特征做triplet损失

## 目标检测

### yolov8

1. 使用DFL loss，用离散积分代替直接估算坐标
2. C2f模块，加强的csp结构
3. 先挑选与gt框得分最高的topk个预测框，并且要保证这些预测框的坐标中心点在gt里面，如果不在，则默认应该由其他坐标中心点去预测，而这个坐标所预测的预测框会被剔除。如果一个预测框同时被多个gt框选中，则取得分最高的gt框作为其正样本
4. 得分计算参考[TOOD: Task-aligned One-stage Object Detection]()，公式是$t=s^{\alpha}*u^{\beta} $。s and u 分别为分类得分和 IoU 值，$\alpha$和$ \beta$分别为是超参数
5. 在求分类损失时，会根据得分重新计算标签。u/max(u) *max(t)，这是一个种归一化，会让不是特别契合的预测框所分配到的gt分类分数越小，属于focal loss的变种。


## 重参数化

基本结论：

1. convbn的组合下，conv的bias会被bn的归一化消除掉，故conv可以不加bias。
